{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%matplotlib.pyplot` not found.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib.pyplot as ple\n",
    "\n",
    "torch.manual_seed(2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(4, 3, num_layers=3)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "input_data = 4\n",
    "hidden_data = 3\n",
    "n_layer =3\n",
    "\n",
    "lstm = nn.LSTM(input_size= input_data, hidden_size = hidden_data , num_layers =n_layer)\n",
    "\n",
    "print(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.8266, -1.1217,  0.1675,  0.3244]]),\n",
       " tensor([[ 0.4140, -0.5388,  0.0123,  0.4103]]),\n",
       " tensor([[-1.3550,  0.2929, -1.3609,  0.2702]]),\n",
       " tensor([[ 0.0588,  0.3933, -0.2182, -0.5292]]),\n",
       " tensor([[-0.2245, -0.4975, -1.4792,  0.7378]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make list of 5 , 4 digit input\n",
    "\n",
    "inputs = [torch.randn(1,input_data) for _ in range(5)]\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out:tensor([[[-0.5256, -0.4391,  0.3034]]], grad_fn=<StackBackward>) with sizetorch.Size([1, 1, 3])\n",
      "hidden (tensor([[[ 0.2528, -0.2185,  0.0890]],\n",
      "\n",
      "        [[ 0.0090,  0.2047, -0.3298]],\n",
      "\n",
      "        [[-0.5256, -0.4391,  0.3034]]], grad_fn=<StackBackward>), tensor([[[ 0.3228, -0.4168,  0.2574]],\n",
      "\n",
      "        [[ 0.0173,  0.3704, -0.5700]],\n",
      "\n",
      "        [[-0.8373, -0.8197,  0.6668]]], grad_fn=<StackBackward>))\n",
      "out:tensor([[[-0.5242, -0.4387,  0.3047]]], grad_fn=<StackBackward>) with sizetorch.Size([1, 1, 3])\n",
      "hidden (tensor([[[ 0.1736, -0.1279,  0.1282]],\n",
      "\n",
      "        [[ 0.0067,  0.2006, -0.3231]],\n",
      "\n",
      "        [[-0.5242, -0.4387,  0.3047]]], grad_fn=<StackBackward>), tensor([[[ 0.2304, -0.2617,  0.3055]],\n",
      "\n",
      "        [[ 0.0128,  0.3701, -0.5597]],\n",
      "\n",
      "        [[-0.8358, -0.8199,  0.6687]]], grad_fn=<StackBackward>))\n",
      "out:tensor([[[-0.5219, -0.4386,  0.3065]]], grad_fn=<StackBackward>) with sizetorch.Size([1, 1, 3])\n",
      "hidden (tensor([[[ 0.1962,  0.0907,  0.3579]],\n",
      "\n",
      "        [[-0.0269,  0.2073, -0.3016]],\n",
      "\n",
      "        [[-0.5219, -0.4386,  0.3065]]], grad_fn=<StackBackward>), tensor([[[ 0.2625,  0.2012,  0.5197]],\n",
      "\n",
      "        [[-0.0505,  0.4061, -0.5293]],\n",
      "\n",
      "        [[-0.8376, -0.8201,  0.6707]]], grad_fn=<StackBackward>))\n",
      "out:tensor([[[-0.5232, -0.4388,  0.3050]]], grad_fn=<StackBackward>) with sizetorch.Size([1, 1, 3])\n",
      "hidden (tensor([[[ 0.1834,  0.0024,  0.2132]],\n",
      "\n",
      "        [[-0.0137,  0.2051, -0.3139]],\n",
      "\n",
      "        [[-0.5232, -0.4388,  0.3050]]], grad_fn=<StackBackward>), tensor([[[ 0.3118,  0.0067,  0.5457]],\n",
      "\n",
      "        [[-0.0261,  0.3921, -0.5453]],\n",
      "\n",
      "        [[-0.8373, -0.8199,  0.6684]]], grad_fn=<StackBackward>))\n",
      "out:tensor([[[-0.5234, -0.4387,  0.3040]]], grad_fn=<StackBackward>) with sizetorch.Size([1, 1, 3])\n",
      "hidden (tensor([[[ 0.0522,  0.0098,  0.0232]],\n",
      "\n",
      "        [[ 0.0012,  0.1958, -0.3247]],\n",
      "\n",
      "        [[-0.5234, -0.4387,  0.3040]]], grad_fn=<StackBackward>), tensor([[[ 0.0598,  0.0155,  0.0339]],\n",
      "\n",
      "        [[ 0.0023,  0.3724, -0.5558]],\n",
      "\n",
      "        [[-0.8347, -0.8198,  0.6665]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "h0 = torch.randn(n_layer,1,hidden_data)\n",
    "c0 = torch.randn(n_layer,1,hidden_data)\n",
    "#h0 = hidden state\n",
    "#c0 = memory state\n",
    "\n",
    "h0 = Variable(h0)\n",
    "c0 = Variable(c0)\n",
    "\n",
    "for i in inputs:\n",
    "    i = Variable(i)\n",
    "    \n",
    "    out,hidden = lstm(i.view(1,1,-1),(h0,c0))\n",
    "    \n",
    "    print(\"out:{} with size{}\".format(out,out.shape))\n",
    "    print(\"hidden\",hidden)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8266, -1.1217,  0.1675,  0.3244]],\n",
      "\n",
      "        [[ 0.4140, -0.5388,  0.0123,  0.4103]],\n",
      "\n",
      "        [[-1.3550,  0.2929, -1.3609,  0.2702]],\n",
      "\n",
      "        [[ 0.0588,  0.3933, -0.2182, -0.5292]],\n",
      "\n",
      "        [[-0.2245, -0.4975, -1.4792,  0.7378]]])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.cat(inputs).view(len(inputs),1,-1)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5256, -0.4391,  0.3034]],\n",
      "\n",
      "        [[-0.4761, -0.5087,  0.0755]],\n",
      "\n",
      "        [[-0.4207, -0.4814, -0.0416]],\n",
      "\n",
      "        [[-0.3908, -0.4575, -0.1207]],\n",
      "\n",
      "        [[-0.3737, -0.4392, -0.1677]]], grad_fn=<StackBackward>)\n",
      "(tensor([[[-0.2533,  0.4384, -0.4539]],\n",
      "\n",
      "        [[ 0.1059,  0.1768, -0.3990]],\n",
      "\n",
      "        [[-0.3737, -0.4392, -0.1677]]], grad_fn=<StackBackward>), tensor([[[-0.2888,  0.7787, -0.7211]],\n",
      "\n",
      "        [[ 0.2212,  0.4414, -0.7037]],\n",
      "\n",
      "        [[-0.5312, -0.6619, -0.5611]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "out,hidden = lstm(inputs,(h0,c0))\n",
    "print(out)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[\n",
    "    (\"The cat ate the cheese\".lower().split(),['DET','NN',\"V\",\"DET\",\"NN\"]),\n",
    "    (\"She read the book\".lower().split(),['NN',\"V\",\"DET\",\"NN\"]),\n",
    "    (\"The dog loves art\".lower().split(),['DET','NN','V','NN']),\n",
    "    (\"The elephant answers the phone\".lower().split(),['DET','NN','V','DET','NN'])\n",
    "]\n",
    "# tuples ma first ko list of words and arko chahi tyo word ko part of speech\n",
    "#DET = Determinant\n",
    "#NN = Noun\n",
    "#V = Verb\n",
    "word2idx = {}\n",
    "\n",
    "for sent,tags in training_data:\n",
    "    for words in sent:\n",
    "        if words not in word2idx:\n",
    "            word2idx[words]=len(word2idx)\n",
    "            \n",
    "tag2idx= {'DET':0,'NN':1,'V':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 0, 'cat': 1, 'ate': 2, 'cheese': 3, 'she': 4, 'read': 5, 'book': 6, 'dog': 7, 'loves': 8, 'art': 9, 'elephant': 10, 'answers': 11, 'phone': 12}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def prepare_sentence(seq,to_idx):\n",
    "    idx = [to_idx[w] for w in seq]\n",
    "    idx = np.array(idx)\n",
    "    return torch.from_numpy(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 11,  0, 12])\n"
     ]
    }
   ],
   "source": [
    "example= prepare_sentence(\"She answers the phone\".lower().split(),word2idx)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 0, 1])\n",
      "tensor([1, 2, 0, 1])\n",
      "tensor([0, 1, 2, 1])\n",
      "tensor([0, 1, 2, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "for sent,tag in training_data:\n",
    "    p=prepare_sentence(tag,tag2idx)\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = [1,2,3]\n",
    "array = np.array(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "    def __init__(self,emb_dim,hidden_dim,vocab_size,tagset_size):\n",
    "        super(LSTMTagger,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embed = nn.Embedding(vocab_size,emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim,hidden_dim)\n",
    "        \n",
    "        self.hidden =self.init_hidden()\n",
    "        \n",
    "        self.hidden2tag = nn.Linear(hidden_dim,tagset_size)\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return(torch.zeros(1,1,self.hidden_dim),torch.zeros(1,1,self.hidden_dim))\n",
    "    #initially hidden ko value 0 rakhne pachi afai update hunxa\n",
    "    def forward(self,sentence):\n",
    "        \n",
    "        embed = self.embed(sentence)\n",
    "        lstm_out, self.hidden = self.lstm(embed.view(len(sentence),1,-1),self.hidden)\n",
    "        \n",
    "        tag_output = self.hidden2tag(lstm_out.view(len(sentence),-1))\n",
    "        #return maximum tag with highest value\n",
    "        tag_scores = F.log_softmax(tag_output,dim=1)\n",
    "        \n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMTagger(\n",
      "  (embed): Embedding(13, 6)\n",
      "  (lstm): LSTM(6, 6)\n",
      "  (hidden2tag): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Embedding_dim = 6\n",
    "Hidden_dim = 6\n",
    "\n",
    "model =LSTMTagger(Embedding_dim,Hidden_dim,len(word2idx),len(tag2idx))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7782, -1.3475, -1.2698],\n",
      "        [-0.7744, -1.3756, -1.2506],\n",
      "        [-0.8299, -1.2837, -1.2486],\n",
      "        [-0.8387, -1.2596, -1.2589]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"The cheese loves elephant\".lower().split()\n",
    "\n",
    "inputs =  prepare_sentence(test_sentence,word2idx)\n",
    "\n",
    "tag_score = model(inputs)\n",
    "print(tag_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "_,prediciton = torch.max(tag_score,dim=1)\n",
    "print(prediciton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20, loss: 0.005272059002891183\n",
      "Epoch : 40, loss: 0.005048574646934867\n",
      "Epoch : 60, loss: 0.0048420707462355494\n",
      "Epoch : 80, loss: 0.004650738439522684\n",
      "Epoch : 100, loss: 0.004473000997677445\n",
      "Epoch : 120, loss: 0.004307505674660206\n",
      "Epoch : 140, loss: 0.0041531105525791645\n",
      "Epoch : 160, loss: 0.004008709860499948\n",
      "Epoch : 180, loss: 0.0038734471308998764\n",
      "Epoch : 200, loss: 0.00374646985437721\n",
      "Epoch : 220, loss: 0.003627113066613674\n",
      "Epoch : 240, loss: 0.003514674899633974\n",
      "Epoch : 260, loss: 0.0034086246159859\n",
      "Epoch : 280, loss: 0.003308426181320101\n",
      "Epoch : 300, loss: 0.003213647403754294\n"
     ]
    }
   ],
   "source": [
    "epochs = 300 \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for sentence,tags in training_data:\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        model.hidden = model.init_hidden()\n",
    "        \n",
    "        sentence_input = prepare_sentence(sentence,word2idx)\n",
    "        \n",
    "        targets = prepare_sentence(tags,tag2idx)\n",
    "        \n",
    "        tag_score = model(sentence_input)\n",
    "        \n",
    "        losses = loss(tag_score,targets)\n",
    "        \n",
    "        running_loss += losses.item()\n",
    "        \n",
    "        losses.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    if(epoch%20 == 19):\n",
    "        print(\"Epoch : {}, loss: {}\".format(epoch+1,running_loss/len(training_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0273, -3.6287, -7.9865],\n",
      "        [-4.4651, -0.0149, -5.7065],\n",
      "        [-6.5411, -3.5574, -0.0304],\n",
      "        [-3.5972, -0.3185, -1.4052]], grad_fn=<LogSoftmaxBackward>)\n",
      "tensor([0, 1, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"The cheese loves elephant\".lower().split()\n",
    "\n",
    "inputs =  prepare_sentence(test_sentence,word2idx)\n",
    "\n",
    "tag_score = model(inputs)\n",
    "print(tag_score)\n",
    "\n",
    "_,prediciton = torch.max(tag_score,dim=1)\n",
    "print(prediciton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
